{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900e6448",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    1. Segmentation result is based on composite/stacking elementary map.\n",
    "    However, legend and the region outside the EDS mapping area need to be cropped out first\n",
    "    2. Afterwards, the matching adjustment or alignment is necessary to make sure the segmented coordinates obtained\n",
    "    from the composite map (multiple elemental maps stacked together) can be used to extract the same grain from the single elementary maps.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96a3f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c1c408",
   "metadata": {},
   "source": [
    "# Single Pair Test - with check of size discrepancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc4bb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_path_list(input_directory, keyword):\n",
    "    \"\"\"\n",
    "        keyword decides the second image in the list\n",
    "    \n",
    "    \"\"\"\n",
    "    # Get a list of all files in the input directory\n",
    "    all_files = os.listdir(input_directory)\n",
    "    \n",
    "    # Filter only image files (assuming .tiff, .png, .jpg extensions)\n",
    "    image_files = [f for f in all_files if f.endswith(('.tiff', '.png', '.jpg', '.jpeg', '.bmp'))]\n",
    "    \n",
    "    # Initialize placeholders for the special cases\n",
    "    elemental_image = None\n",
    "    keyword_image = None\n",
    "    other_images = []\n",
    "\n",
    "    # Loop through image files and classify them\n",
    "    for image_file in image_files:\n",
    "        if 'Elemental' in image_file:\n",
    "            elemental_image = image_file\n",
    "        elif keyword in image_file:\n",
    "            keyword_image = image_file\n",
    "        else:\n",
    "            other_images.append(image_file)\n",
    "\n",
    "    # Start building the final image path list\n",
    "    image_path_list = []\n",
    "\n",
    "    # Add 'Elemental' image first if it exists\n",
    "    if elemental_image:\n",
    "        image_path_list.append(os.path.join(input_directory, elemental_image))\n",
    "\n",
    "    # Add keyword-based image second if it exists\n",
    "    if keyword_image:\n",
    "        image_path_list.append(os.path.join(input_directory, keyword_image))\n",
    "\n",
    "    # Add the remaining casual images\n",
    "    for other_image in other_images:\n",
    "        image_path_list.append(os.path.join(input_directory, other_image))\n",
    "\n",
    "    # Output and print the final image path list\n",
    "    print(\"Generated Image Path List:\")\n",
    "    for path in image_path_list:\n",
    "        print(path)\n",
    "\n",
    "    return image_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eee7bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    the keyword was 'Si' in this case, so in the generated list, it's the second image. That's just my preference of always comparing with Si map with the composite map first.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ba45b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Image Path List:\n",
      "To_be_Aligned\\USU-4183B 150-250 Elemental Map.jpeg\n",
      "To_be_Aligned\\USU-4183B 150-250 Si Map.jpeg\n",
      "To_be_Aligned\\USU-4183B 150-250 Al Map.jpeg\n",
      "To_be_Aligned\\USU-4183B 150-250 Ca Map.jpeg\n",
      "To_be_Aligned\\USU-4183B 150-250 Fe Map.jpeg\n",
      "To_be_Aligned\\USU-4183B 150-250 K Map.jpeg\n",
      "To_be_Aligned\\USU-4183B 150-250 Na Map.jpeg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n    the keyward was 'Si' in this case, so in the generated list, it's the second image. That's just my preference of always comparing with Si map with the composite map first.\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage:\n",
    "input_directory = 'To_be_Aligned'  # Specify your input directory\n",
    "image_paths = generate_image_path_list(input_directory, keyword='Si')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf57d80e",
   "metadata": {},
   "source": [
    "# Single Pair Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da06e861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_images_with_affine(image1, image2):\n",
    "    # Convert images to grayscale\n",
    "    gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Initialize ORB detector\n",
    "    orb = cv2.ORB_create(nfeatures=5000)\n",
    "\n",
    "    # Detect key points and descriptors\n",
    "    keypoints1, descriptors1 = orb.detectAndCompute(gray1, None)\n",
    "    keypoints2, descriptors2 = orb.detectAndCompute(gray2, None)\n",
    "\n",
    "    # Create BFMatcher object\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    # Match descriptors\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "\n",
    "    # Sort matches by distance and retain the best ones\n",
    "    matches = sorted(matches, key=lambda x: x.distance)[:30]  # Use the top 30 matches\n",
    "\n",
    "    # Extract locations of good matches\n",
    "    points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "    points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "    for i, match in enumerate(matches):\n",
    "        points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "        points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "\n",
    "    # Find the affine transformation (instead of homography) for simplicity in alignment\n",
    "    affine_matrix, mask = cv2.estimateAffinePartial2D(points2, points1, method=cv2.RANSAC)\n",
    "\n",
    "    # Use the affine transformation to warp image2 to align with image1\n",
    "    height, width, channels = image1.shape\n",
    "    aligned_image2 = cv2.warpAffine(image2, affine_matrix, (width, height))\n",
    "\n",
    "    return aligned_image2, affine_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c891e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All aligned images have been saved in the directory: Aligned\\USU-4183B 150-250 Elemental Map\n"
     ]
    }
   ],
   "source": [
    "# Main function\n",
    "def main():\n",
    "    \"\"\"\n",
    "    The first in the image list is the composite image;\n",
    "    the second is the main referenced image.\n",
    "    \"\"\"\n",
    "    # Read the images\n",
    "    images = [cv2.imread(path) for path in image_paths]\n",
    "    \n",
    "    # Use the first two images for initial alignment calculation\n",
    "    composite_image = images[0]\n",
    "    imageA = images[1]\n",
    "    aligned_imageA, affine_matrix = align_images_with_affine(composite_image, imageA)\n",
    "\n",
    "    # Create output directory named after the composite image under 'Aligned'\n",
    "    composite_image_name = os.path.basename(image_paths[0]).split('.')[0]\n",
    "    output_dir = os.path.join('Aligned', composite_image_name)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Save the aligned composite image and aligned imageA\n",
    "    cv2.imwrite(os.path.join(output_dir, f\"{composite_image_name}_aligned.png\"), composite_image)\n",
    "    cv2.imwrite(os.path.join(output_dir, f\"{os.path.splitext(os.path.basename(image_paths[1]))[0]}_aligned.png\"), aligned_imageA)\n",
    "\n",
    "    # Apply the same affine transformation to the rest of the images and save them\n",
    "    for image_path in image_paths[2:]:\n",
    "        image = cv2.imread(image_path)\n",
    "        aligned_image = cv2.warpAffine(image, affine_matrix, (composite_image.shape[1], composite_image.shape[0]))\n",
    "        \n",
    "        aligned_image_path = os.path.join(output_dir, f\"{os.path.splitext(os.path.basename(image_path))[0]}_aligned.png\")\n",
    "        cv2.imwrite(aligned_image_path, aligned_image)\n",
    "\n",
    "    print(f\"All aligned images have been saved in the directory: {output_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829d4a21",
   "metadata": {},
   "source": [
    "**Always manually check the alignment result after running this notebook.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
